{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "012ce352-8408-4ee7-a137-b777c4b7070c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# source = inspect.getsource(train)\n",
    "# parsed = ast.parse(source)\n",
    "\n",
    "# for node in ast.walk(parsed):\n",
    "#     if isinstance(node,ast.Call):\n",
    "#         if isinstance(node.func, ast.Attribute):\n",
    "#             if (node.func.value.id == 'layer'):\n",
    "#                     if(node.func.attr == 'get_dataset'):\n",
    "#                         print(ast.dump(node))\n",
    "#                         print(node.args[0].value)\n",
    "\n",
    "\n",
    "# ast.dump(parsed)\n",
    "\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import ast\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    entities = []\n",
    "    entity_context = None\n",
    "\n",
    "    def __init__(self, project_name, environment):\n",
    "        self.project_name = project_name\n",
    "        self.environment = environment\n",
    "\n",
    "    def setup(self):\n",
    "        if os.path.exists(self.environment):\n",
    "            file1 = open(self.environment, 'r')\n",
    "            for lib in file1.readlines():\n",
    "                print(f\"Layer Infra: Installing {lib.strip()}...\")\n",
    "        else:\n",
    "            print(f\"Environment file not found: {self.environment}\")\n",
    "\n",
    "    def log_parameter(self, metric, value):\n",
    "        print(f\"\\t{Layer.entity_context} > Parameter > {metric}:{value}\")\n",
    "\n",
    "    def log_metric(self, metric, value):\n",
    "        print(f\"\\t{Layer.entity_context} > Metric >{metric}:{value}\")\n",
    "\n",
    "    def log(self, message):\n",
    "        print(f\"\\t{Layer.entity_context} > {message}\")\n",
    "\n",
    "    def run(self, entities):\n",
    "        self.entities = []\n",
    "        for entity in entities:\n",
    "            if entity._type == \"dataset\":\n",
    "                self.entities.append(Dataset(entity))\n",
    "            elif entity._type == \"model\":\n",
    "                self.entities.append(Model(entity))\n",
    "\n",
    "        print(f\"--- Layer Infra: Running Project: {self.project_name} ---\")\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "        for entity in self.entities:\n",
    "            entity.run()\n",
    "        print(f\"\\n--- Layer Infra: Run Complete! ---\")\n",
    "\n",
    "    def get_dataset(self, name):\n",
    "        for entity in self.entities:\n",
    "            if entity.name == name:\n",
    "                return entity\n",
    "        raise Exception(f\"Entity '{name}' not found!\")\n",
    "\n",
    "\n",
    "class Model:\n",
    "    result = None\n",
    "\n",
    "    def __init__(self, func):\n",
    "        if func:\n",
    "            self.name = func._name\n",
    "            self.func = func\n",
    "\n",
    "    def run(self):\n",
    "        self.result = self.func()\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    result = None\n",
    "\n",
    "    def __init__(self, func):\n",
    "        if func:\n",
    "            self.name = func._name\n",
    "            self.func = func\n",
    "\n",
    "    def run(self):\n",
    "        self.result = self.func()\n",
    "\n",
    "    def to_pandas(self):\n",
    "        return self.result\n",
    "\n",
    "\n",
    "def dataset(name):\n",
    "    def inner(func):\n",
    "        func._type = \"dataset\"\n",
    "        func._name = name\n",
    "\n",
    "        def wrapped(*args):\n",
    "            Layer.entity_context = func._name\n",
    "            print(f'\\nBuilding {Layer.entity_context}...')\n",
    "            res = func()\n",
    "            # TODO save returning entity to catalog\n",
    "            return res\n",
    "        wrapped._type = \"dataset\"\n",
    "        wrapped._name = name\n",
    "\n",
    "        return wrapped\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "def model(name):\n",
    "    def inner(func):\n",
    "        def wrapped(*args):\n",
    "            Layer.entity_context = name\n",
    "            print(f'\\nTraining {Layer.entity_context}...')\n",
    "            res = func()\n",
    "            # TODO save returning entity to catalog\n",
    "            return res\n",
    "        wrapped._type = \"model\"\n",
    "        wrapped._name = name\n",
    "\n",
    "        return wrapped\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f4c063f-7b7a-402e-a0bc-4541503f00ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Layer Infra: Running Project: ltv_project ---\n",
      "Layer Infra: Installing scikit-learn>=0.18...\n",
      "\n",
      "Building raw_passengers...\n",
      "\traw_passengers > Total passengers: 891\n",
      "\n",
      "Building features...\n",
      "\tfeatures > Features: ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "\tfeatures > Total Count: 891\n",
      "\n",
      "Training survival_model...\n",
      "\tsurvival_model > Training data count: 891\n",
      "\tsurvival_model > Metric >accuracy:0.8045\n",
      "\n",
      "--- Layer Infra: Run Complete! ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataset(\"dummy_dataset\")\n",
    "def build_dummy():\n",
    "    data = [[1, 'tom', '01011999'], [2, 'nick', '01011983'],\n",
    "            [3, 'juli', '01012002']]\n",
    "    columns = ['id', 'name', 'birth']\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "@dataset('raw_passengers')\n",
    "def read_and_clean_dataset():\n",
    "    df = pd.read_csv(\"titanic.csv\")\n",
    "    layer.log(f\"Total passengers: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_sex(sex):\n",
    "    result = 0\n",
    "    if sex == \"female\":\n",
    "        result = 0\n",
    "    elif sex == \"male\":\n",
    "        result = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def clean_age(data):\n",
    "    age = data[0]\n",
    "    pclass = data[1]\n",
    "    if pd.isnull(age):\n",
    "        if pclass == 1:\n",
    "            return 37\n",
    "        elif pclass == 2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 24\n",
    "    else:\n",
    "        return age\n",
    "\n",
    "\n",
    "@dataset('features')\n",
    "def extract_features():\n",
    "    df = layer.get_dataset(\"raw_passengers\").to_pandas()\n",
    "\n",
    "    df['Sex'] = df['Sex'].apply(clean_sex)\n",
    "    df['Age'] = df[['Age', 'Pclass']].apply(clean_age, axis=1)\n",
    "\n",
    "    df = df.drop([\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\", \"Embarked\"], axis=1)\n",
    "\n",
    "    layer.log(f'Features: {list(df.columns)}')\n",
    "    layer.log(f'Total Count: {len(df)}')\n",
    "    return df\n",
    "\n",
    "\n",
    "@model(name='survival_model')\n",
    "def train():\n",
    "    df = layer.get_dataset(\"features\").to_pandas()\n",
    "    layer.log(f\"Training data count: {len(df)}\")\n",
    "\n",
    "    X = df.drop([\"Survived\"], axis=1)\n",
    "    y = df[\"Survived\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=100)\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    layer.log_metric(\"accuracy\", f'{acc:.4f}')\n",
    "    return random_forest\n",
    "\n",
    "\n",
    "# ++ init Layer\n",
    "layer = Layer(project_name=\"ltv_project\", environment='requirements.txt')\n",
    "\n",
    "# ++ To run the whole project on Layer Infra\n",
    "layer.run([read_and_clean_dataset, extract_features, train])\n",
    "\n",
    "# ++ To train model on Layer infra\n",
    "# layer.run([train])\n",
    "\n",
    "# ++ To debug the code locally, just call the function:\n",
    "# train()\n",
    "# extract_features()\n",
    "\n",
    "# read_and_clean_dataset()\n",
    "# train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
